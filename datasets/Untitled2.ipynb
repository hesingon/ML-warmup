{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- time to load and select datasets: 0.370768070221 seconds ---\n",
      "--- time to normalize: 0.0338640213013 seconds ---\n",
      "--- time to segment: 0.433979988098 seconds ---\n",
      "--- time to extract features: 2.50458693504 seconds ---\n",
      "In the 0 fold, the classification accuracy is 0.751479\n",
      "And the confusion matrix is: \n",
      "[[301   1  49   2   3]\n",
      " [  4  45  15   9  17]\n",
      " [ 98   5 233   4   0]\n",
      " [  5  24   7  30  23]\n",
      " [  0  11   4  13 280]]\n",
      "In the 1 fold, the classification accuracy is 0.730347\n",
      "And the confusion matrix is: \n",
      "[[286   4  59   5   2]\n",
      " [  7  44  16  14   7]\n",
      " [121  10 210   2   2]\n",
      " [  5  26  10  43  13]\n",
      " [  1   5   4   6 281]]\n",
      "In the 2 fold, the classification accuracy is 0.752325\n",
      "And the confusion matrix is: \n",
      "[[284   1  47   3   2]\n",
      " [  4  34  14  22  10]\n",
      " [117   7 223   2   1]\n",
      " [  1  12   9  47  18]\n",
      " [  0   4   3  16 302]]\n",
      "In the 3 fold, the classification accuracy is 0.732037\n",
      "And the confusion matrix is: \n",
      "[[304   5  64   3   2]\n",
      " [  5  30  13  20  13]\n",
      " [102   2 195   4   1]\n",
      " [ 11  13  12  32  19]\n",
      " [  2   8   1  17 305]]\n",
      "In the 4 fold, the classification accuracy is 0.764159\n",
      "And the confusion matrix is: \n",
      "[[322   3  51   1   2]\n",
      " [  4  44  14  14   8]\n",
      " [104   6 215   3   0]\n",
      " [  2  21  10  32  17]\n",
      " [  0  11   4   4 291]]\n",
      "In the 5 fold, the classification accuracy is 0.730347\n",
      "And the confusion matrix is: \n",
      "[[288   1  61   4   2]\n",
      " [  5  40  17  15  14]\n",
      " [ 98   3 237   1   4]\n",
      " [  0  17  19  35  25]\n",
      " [  1  14   7  11 264]]\n",
      "In the 6 fold, the classification accuracy is 0.747253\n",
      "And the confusion matrix is: \n",
      "[[293   2  57   1   1]\n",
      " [  4  46  11  22   6]\n",
      " [129   6 195   4   1]\n",
      " [  2   8   9  46  13]\n",
      " [  4   6   3  10 304]]\n",
      "In the 7 fold, the classification accuracy is 0.744717\n",
      "And the confusion matrix is: \n",
      "[[309   2  48   1   3]\n",
      " [  3  29  24  11  13]\n",
      " [120   8 219   4   2]\n",
      " [  4   9   9  43  17]\n",
      " [  0  10   4  10 281]]\n",
      "In the 8 fold, the classification accuracy is 0.701606\n",
      "And the confusion matrix is: \n",
      "[[316   2  62   1   2]\n",
      " [  4  44  20  11   4]\n",
      " [134   8 173   1   5]\n",
      " [  1  22  19  25  35]\n",
      " [  2   8   4   8 272]]\n",
      "In the 9 fold, the classification accuracy is 0.757396\n",
      "And the confusion matrix is: \n",
      "[[309   1  43   2   0]\n",
      " [  1  33  14  14  13]\n",
      " [122   9 229   3   1]\n",
      " [  2  18  18  39  10]\n",
      " [  0   9   2   5 286]]\n",
      "--- time to extract features: 23.4814901352 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# description of this dataset http://groupware.les.inf.puc-rio.br/har#ixzz2PyRdbAfA\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "le = pp.LabelEncoder() \n",
    "le.fit(['sitting', 'walking', 'sittingdown', 'standing', 'standingup'])\n",
    "\n",
    "initial = time.time()\n",
    "### Retrieving all data\n",
    "overall = pd.read_csv(\"./dataset-har-PUC-Rio-ugulino.csv\", delimiter=';', header='infer') \n",
    "data = overall.loc[:, \"x1\":\"z4\"].as_matrix() # has to be converted to ndarray in order to be processed by segment_signal()\n",
    "targets = overall.loc[:,\"class,,\"].as_matrix() # double commas: looks like the researchers are naughty\n",
    "\n",
    "load = time.time()\n",
    "print \"--- time to load and select datasets: %s seconds ---\" % (load - initial)\n",
    "\n",
    "\n",
    "### Data segmentation: shall use a sudden change of sensor readings\n",
    "### like if (x_pre - x_curr <= 1.0, do nothing)\n",
    "### Range of Accelerometer sensor readings is +3g/-3g\n",
    "\n",
    "# reading 14 sets of data in every 2 seconds. \n",
    "# For segmenting the data from online only. \n",
    "# each set of data is taken 150ms apart from another.\n",
    "# so choosing a window size of 14 will be 2.1 seconds.\n",
    "\n",
    "\n",
    "def segment_signal(data, window_size=14): \n",
    "\n",
    "    N = data.shape[0]\n",
    "    dim = data.shape[1]\n",
    "    K = N/window_size\n",
    "    segments = numpy.empty((K, window_size, dim))\n",
    "    for i in range(K):\n",
    "        segment = data[i*window_size:i*window_size+window_size,:]\n",
    "        segments[i] = numpy.vstack(segment)\n",
    "    return segments\n",
    "\n",
    "\n",
    "\n",
    "##!!!! questions: for normalization, should it be done right after loading csv or after segmenation? \n",
    "##!!!! Normalize() can't process nadarray with dimension > 2.\n",
    "X = pp.normalize(data)\n",
    "y = targets[::14] \n",
    "y = y[:-1]# -1 because it will have a extra set of data than X.\n",
    "\n",
    "normalizing = time.time()\n",
    "print \"--- time to normalize: %s seconds ---\" % (normalizing - load)\n",
    "\n",
    "segs = segment_signal(X)\n",
    "\n",
    "segmenting = time.time()\n",
    "print \"--- time to segment: %s seconds ---\" % (segmenting - normalizing)\n",
    "\n",
    "### feautre extraction // take the difference between sensors\n",
    "\n",
    "### this method is to extract the difference between consecutive sensor readings.\n",
    "## parameter raw is a 2D ndarray\n",
    "## return a 2D ndarray\n",
    "def extract_diff(raw):\n",
    "\n",
    "    N = raw.shape[0] # number of sets of sensor readings\n",
    "    dim = raw.shape[1] # number of values in each readings\n",
    "    features = numpy.empty((N - 1, dim))\n",
    "    for i in range(1, N):\n",
    "        for j in range(dim):\n",
    "            features[i-1][j] = raw[i][j] - raw[i-1][j]\n",
    "\n",
    "    return features\n",
    "\n",
    "def extract_diff_2(raw):\n",
    "\n",
    "    N = raw.shape[0] # number of segments of sensor readings ()\n",
    "    I = raw.shape[1] # number of sets of readings (14)\n",
    "    J = raw.shape[2] # number of values in each set of readings (12)\n",
    "    feature_num = (I - 1) * J\n",
    "    feature = numpy.empty((feature_num))\n",
    "    features = numpy.empty((N, feature_num))\n",
    "    for n in range(N):\n",
    "        idx = 0;\n",
    "        for i in range(1, I):\n",
    "            for j in range(J):\n",
    "                feature[idx] = raw[n][i][j] - raw[n][i-1][j]\n",
    "                idx += 1\n",
    "        features[n] = feature\n",
    "        \n",
    "\n",
    "    return features\n",
    "\n",
    "features = extract_diff_2(segs)\n",
    "\n",
    "extracting_feature = time.time()\n",
    "print \"--- time to extract features: %s seconds ---\" % (extracting_feature - segmenting)\n",
    "\n",
    "#having 15 neurons\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "fold_index = 0\n",
    "for train, test in kfold.split(features):\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(15,), random_state=1).fit(features[train], y[train])\n",
    "    predictions = clf.predict(features[test])\n",
    "    accuracy = clf.score(features[test], y[test])\n",
    "    cm = confusion_matrix(y[test], predictions)\n",
    "\n",
    "    print('In the %i fold, the classification accuracy is %f' %(fold_index, accuracy))\n",
    "    print('And the confusion matrix is: ')\n",
    "    print(cm)\n",
    "    fold_index += 1\n",
    "\n",
    "\n",
    "evaluate_model = time.time()\n",
    "print \"--- time to extract features: %s seconds ---\" % (evaluate_model - extracting_feature)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
